{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIRUPVKOfox4nV8+R9TW5b"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E_7WIoHfdUzT"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams['figure.figsize'] = (10, 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivAZE2T1dZoz",
        "outputId": "4b9ad479-62b3-4d77-db05-5aa72f8ee4c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 경로 지정\n",
        "file_path = '/content/drive/MyDrive/ITStudy/09_MLDL/team_pj/bank.csv'\n",
        "\n",
        "# CSV 파일 읽기\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# 데이터 확인\n",
        "print(data)\n",
        "\n",
        "## 총 11162개의 관측치와 17개의 변수가 있음\n",
        "## job, education, contact, poutcome 변수에 결측값(여기서는 \"unknown\"으로 표시된 값)이 있다는 점을 알 수 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDIXAPrBdbJt",
        "outputId": "31434597-ec2f-42ac-e5d9-476e88fcfb5e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       age          job  marital  education default  balance housing loan  \\\n",
            "0       59       admin.  married  secondary      no     2343     yes   no   \n",
            "1       56       admin.  married  secondary      no       45      no   no   \n",
            "2       41   technician  married  secondary      no     1270     yes   no   \n",
            "3       55     services  married  secondary      no     2476     yes   no   \n",
            "4       54       admin.  married   tertiary      no      184      no   no   \n",
            "...    ...          ...      ...        ...     ...      ...     ...  ...   \n",
            "11157   33  blue-collar   single    primary      no        1     yes   no   \n",
            "11158   39     services  married  secondary      no      733      no   no   \n",
            "11159   32   technician   single  secondary      no       29      no   no   \n",
            "11160   43   technician  married  secondary      no        0      no  yes   \n",
            "11161   34   technician  married  secondary      no        0      no   no   \n",
            "\n",
            "        contact  day month  duration  campaign  pdays  previous poutcome  \\\n",
            "0       unknown    5   may      1042         1     -1         0  unknown   \n",
            "1       unknown    5   may      1467         1     -1         0  unknown   \n",
            "2       unknown    5   may      1389         1     -1         0  unknown   \n",
            "3       unknown    5   may       579         1     -1         0  unknown   \n",
            "4       unknown    5   may       673         2     -1         0  unknown   \n",
            "...         ...  ...   ...       ...       ...    ...       ...      ...   \n",
            "11157  cellular   20   apr       257         1     -1         0  unknown   \n",
            "11158   unknown   16   jun        83         4     -1         0  unknown   \n",
            "11159  cellular   19   aug       156         2     -1         0  unknown   \n",
            "11160  cellular    8   may         9         2    172         5  failure   \n",
            "11161  cellular    9   jul       628         1     -1         0  unknown   \n",
            "\n",
            "      deposit  \n",
            "0         yes  \n",
            "1         yes  \n",
            "2         yes  \n",
            "3         yes  \n",
            "4         yes  \n",
            "...       ...  \n",
            "11157      no  \n",
            "11158      no  \n",
            "11159      no  \n",
            "11160      no  \n",
            "11161      no  \n",
            "\n",
            "[11162 rows x 17 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In45WkPxddI9",
        "outputId": "abc68cd4-0156-4e72-f771-e3615883ed70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
              "       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n",
              "       'previous', 'poutcome', 'deposit'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()\n",
        "## 10개의 범주형 특성과 7개의 수치형 특성이 있다는 것을 확인 가능\n",
        "## 또한, 어떤 열에도 null 값은 없지만 앞서 언급한 대로 일부 열에는 결측값이 존재"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od9xdxgPdi1d",
        "outputId": "3fce400b-62f1-4536-d237-cc6e631cbba3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11162 entries, 0 to 11161\n",
            "Data columns (total 17 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   age        11162 non-null  int64 \n",
            " 1   job        11162 non-null  object\n",
            " 2   marital    11162 non-null  object\n",
            " 3   education  11162 non-null  object\n",
            " 4   default    11162 non-null  object\n",
            " 5   balance    11162 non-null  int64 \n",
            " 6   housing    11162 non-null  object\n",
            " 7   loan       11162 non-null  object\n",
            " 8   contact    11162 non-null  object\n",
            " 9   day        11162 non-null  int64 \n",
            " 10  month      11162 non-null  object\n",
            " 11  duration   11162 non-null  int64 \n",
            " 12  campaign   11162 non-null  int64 \n",
            " 13  pdays      11162 non-null  int64 \n",
            " 14  previous   11162 non-null  int64 \n",
            " 15  poutcome   11162 non-null  object\n",
            " 16  deposit    11162 non-null  object\n",
            "dtypes: int64(7), object(10)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이상치 및 결측치 수동제거에 따른 모델 변화\n"
      ],
      "metadata": {
        "id": "3AC3E8fA1xHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이상치 및 결측치 제거 전\n",
        "- 사용 모델: RandomForestClassifier\n",
        "- 선택된 변수: Index(['age', 'job', 'balance', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'poutcome'], dtype='object')\n",
        "- 모델 정확도: 0.8351992834751455\n",
        "\n",
        "> 정규화: StandardScaler\n",
        ">\n",
        "> test_size=0.2, random_state=42"
      ],
      "metadata": {
        "id": "eN7UHcY70CMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature와 Target 설정\n",
        "X = data.drop('deposit', axis=1)\n",
        "y = data['deposit']\n",
        "\n",
        "# Train/Test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# RandomForestClassifier 초기화\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Recursive Feature Elimination (RFE)를 이용한 feature selection\n",
        "rfe_selector = RFE(estimator=rf_classifier, n_features_to_select=10, step=1)\n",
        "rfe_selector = rfe_selector.fit(X_train, y_train)\n",
        "\n",
        "# 선택된 특징으로 학습\n",
        "selected_features = X_train.columns[rfe_selector.support_]\n",
        "rf_classifier.fit(X_train[selected_features], y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = rf_classifier.predict(X_test[selected_features])\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"선택된 변수: {selected_features}\")\n",
        "print(f\"모델 정확도: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A61JvS-ddlwh",
        "outputId": "8d456d66-8689-4922-aa7f-4290ec5d8b9f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "선택된 특징: Index(['age', 'job', 'balance', 'contact', 'day', 'month', 'duration',\n",
            "       'campaign', 'pdays', 'poutcome'],\n",
            "      dtype='object')\n",
            "모델 정확도: 0.8351992834751455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이상치 및 결측치 제거 (age, job)\n",
        "- 사용 모델: RandomForestClassifier\n",
        "- 선택된 변수: age', 'job', 'balance', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'poutcome'\n",
        "- 모델 정확도: 0.8441325768886234\n",
        "\n",
        "> 정규화: StandardScaler\n",
        ">\n",
        "> test_size=0.3, random_state=42"
      ],
      "metadata": {
        "id": "O8NwUZAI0rbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "# 70세 이상은 이상치로 제거\n",
        "data = data[data['age'] <= 70]\n",
        "\n",
        "# 'job' 칼럼에서 'unknown' 값을 결측치로 처리\n",
        "data['job'] = data['job'].replace('unknown', None)\n",
        "\n",
        "# SimpleImputer로 결측치를 처리 (최빈값으로 대체)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data['job'] = imputer.fit_transform(data[['job']])\n",
        "\n",
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature와 Target 설정\n",
        "X = data.drop('deposit', axis=1)\n",
        "y = data['deposit']\n",
        "\n",
        "# Train/Test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# RandomForestClassifier 초기화\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Recursive Feature Elimination (RFE)를 이용한 feature selection\n",
        "rfe_selector = RFE(estimator=rf_classifier, n_features_to_select=10, step=1)\n",
        "rfe_selector = rfe_selector.fit(X_train, y_train)\n",
        "\n",
        "# 선택된 특징으로 학습\n",
        "selected_features = X_train.columns[rfe_selector.support_]\n",
        "rf_classifier.fit(X_train[selected_features], y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = rf_classifier.predict(X_test[selected_features])\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"선택된 특징: {selected_features}\")\n",
        "print(f\"모델 정확도: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqzA1MpydnWr",
        "outputId": "c8ad5f2b-cf9d-4d7f-eb1a-5a480965d83b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "선택된 특징: Index(['age', 'job', 'balance', 'contact', 'day', 'month', 'duration',\n",
            "       'campaign', 'pdays', 'poutcome'],\n",
            "      dtype='object')\n",
            "모델 정확도: 0.8441325768886234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이상치 및 결측치 제거 (age, job)\n",
        "- 사용 모델: GradientBoostingClassifier\n",
        "- 선택된 변수: age', 'job', 'balance', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'poutcome'\n",
        "- 모델 정확도: 0.8348760824126605\n",
        "\n",
        "> 정규화: StandardScaler\n",
        ">\n",
        "> test_size=0.3, random_state=42"
      ],
      "metadata": {
        "id": "6TmTEG0V08uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "# 70세 이상은 이상치로 제거\n",
        "data = data[data['age'] <= 70]\n",
        "\n",
        "# 'job' 칼럼에서 'unknown' 값을 결측치로 처리\n",
        "data['job'] = data['job'].replace('unknown', None)\n",
        "\n",
        "# SimpleImputer로 결측치를 처리 (최빈값으로 대체)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data['job'] = imputer.fit_transform(data[['job']])\n",
        "\n",
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature와 Target 설정\n",
        "X = data.drop('deposit', axis=1)\n",
        "y = data['deposit']\n",
        "\n",
        "# Train/Test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# GradientBoostingClassifier 초기화\n",
        "rf_classifier = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Recursive Feature Elimination (RFE)를 이용한 feature selection\n",
        "rfe_selector = RFE(estimator=rf_classifier, n_features_to_select=10, step=1)\n",
        "rfe_selector = rfe_selector.fit(X_train, y_train)\n",
        "\n",
        "# 선택된 특징으로 학습\n",
        "selected_features = X_train.columns[rfe_selector.support_]\n",
        "rf_classifier.fit(X_train[selected_features], y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = rf_classifier.predict(X_test[selected_features])\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"선택된 특징: {selected_features}\")\n",
        "print(f\"모델 정확도: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj-L2BB3yDaS",
        "outputId": "1a5d06fe-6909-431e-962e-46da94fa404b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "선택된 특징: Index(['age', 'balance', 'housing', 'contact', 'day', 'month', 'duration',\n",
            "       'pdays', 'previous', 'poutcome'],\n",
            "      dtype='object')\n",
            "모델 정확도: 0.8348760824126605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이상치 및 결측치 제거 (age, job)\n",
        "- 사용 모델: lightgbm\n",
        "- 선택된 변수: 'age', 'job', 'balance', 'housing', 'contact', 'day', 'month','duration', 'campaign', 'pdays'\n",
        "- 모델 정확도: 0.8518960883845924\n",
        "\n",
        "> 정규화: StandardScaler\n",
        ">\n",
        "> test_size=0.3, random_state=42"
      ],
      "metadata": {
        "id": "GR08mNGF1FTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import lightgbm as lgb\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "# 70세 이상은 이상치로 제거\n",
        "data = data[data['age'] <= 70]\n",
        "\n",
        "# 'job' 칼럼에서 'unknown' 값을 결측치로 처리\n",
        "data['job'] = data['job'].replace('unknown', None)\n",
        "\n",
        "# SimpleImputer로 결측치를 처리 (최빈값으로 대체)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data['job'] = imputer.fit_transform(data[['job']])\n",
        "\n",
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature와 Target 설정\n",
        "X = data.drop('deposit', axis=1)\n",
        "y = data['deposit']\n",
        "\n",
        "# Train/Test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# LightGBM 모델 초기화\n",
        "lgb_classifier = lgb.LGBMClassifier(random_state=42)\n",
        "\n",
        "# Recursive Feature Elimination (RFE)를 이용한 feature selection\n",
        "rfe_selector = RFE(estimator=lgb_classifier, n_features_to_select=10, step=1)\n",
        "rfe_selector = rfe_selector.fit(X_train, y_train)\n",
        "\n",
        "# 선택된 특징으로 학습\n",
        "selected_features = X_train.columns[rfe_selector.support_]\n",
        "lgb_classifier.fit(X_train[selected_features], y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = lgb_classifier.predict(X_test[selected_features])\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"선택된 특징: {selected_features}\")\n",
        "print(f\"모델 정확도: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuP6whYgy0Ox",
        "outputId": "f60edabc-c6ec-4ca8-8d3b-d72d7b063f49"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3682, number of negative: 4131\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001702 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 964\n",
            "[LightGBM] [Info] Number of data points in the train set: 7813, number of used features: 16\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.471266 -> initscore=-0.115063\n",
            "[LightGBM] [Info] Start training from score -0.115063\n",
            "[LightGBM] [Info] Number of positive: 3682, number of negative: 4131\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001104 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 962\n",
            "[LightGBM] [Info] Number of data points in the train set: 7813, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.471266 -> initscore=-0.115063\n",
            "[LightGBM] [Info] Start training from score -0.115063\n",
            "[LightGBM] [Info] Number of positive: 3682, number of negative: 4131\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 960\n",
            "[LightGBM] [Info] Number of data points in the train set: 7813, number of used features: 14\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.471266 -> initscore=-0.115063\n",
            "[LightGBM] [Info] Start training from score -0.115063\n",
            "[LightGBM] [Info] Number of positive: 3682, number of negative: 4131\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 937\n",
            "[LightGBM] [Info] Number of data points in the train set: 7813, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.471266 -> initscore=-0.115063\n",
            "[LightGBM] [Info] Start training from score -0.115063\n",
            "[LightGBM] [Info] Number of positive: 3682, number of negative: 4131\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 933\n",
            "[LightGBM] [Info] Number of data points in the train set: 7813, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.471266 -> initscore=-0.115063\n",
            "[LightGBM] [Info] Start training from score -0.115063\n",
            "[LightGBM] [Info] Number of positive: 3682, number of negative: 4131\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 930\n",
            "[LightGBM] [Info] Number of data points in the train set: 7813, number of used features: 11\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.471266 -> initscore=-0.115063\n",
            "[LightGBM] [Info] Start training from score -0.115063\n",
            "[LightGBM] [Info] Number of positive: 3682, number of negative: 4131\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000804 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 926\n",
            "[LightGBM] [Info] Number of data points in the train set: 7813, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.471266 -> initscore=-0.115063\n",
            "[LightGBM] [Info] Start training from score -0.115063\n",
            "[LightGBM] [Info] Number of positive: 3682, number of negative: 4131\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 926\n",
            "[LightGBM] [Info] Number of data points in the train set: 7813, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.471266 -> initscore=-0.115063\n",
            "[LightGBM] [Info] Start training from score -0.115063\n",
            "선택된 특징: Index(['age', 'job', 'balance', 'housing', 'contact', 'day', 'month',\n",
            "       'duration', 'campaign', 'pdays'],\n",
            "      dtype='object')\n",
            "모델 정확도: 0.8518960883845924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 이상치 및 결측치 제거 (age, job)\n",
        "- 사용 모델: xgboost\n",
        "- 선택된 변수: 'education', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'pdays', 'previous', 'poutcome'\n",
        "- 모델 정확도: 0.8542848611525828\n",
        "\n",
        "> 정규화: StandardScaler\n",
        ">\n",
        "> test_size=0.3, random_state=42"
      ],
      "metadata": {
        "id": "5hRdsUjH2OIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import xgboost as xgb\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "# 70세 이상은 이상치로 제거\n",
        "data = data[data['age'] <= 70]\n",
        "\n",
        "# 'job' 칼럼에서 'unknown' 값을 결측치로 처리\n",
        "data['job'] = data['job'].replace('unknown', None)\n",
        "\n",
        "# SimpleImputer로 결측치를 처리 (최빈값으로 대체)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data['job'] = imputer.fit_transform(data[['job']])\n",
        "\n",
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature와 Target 설정\n",
        "X = data.drop('deposit', axis=1)\n",
        "y = data['deposit']\n",
        "\n",
        "# Train/Test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# XGBoost 모델 초기화\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Recursive Feature Elimination (RFE)를 이용한 feature selection\n",
        "rfe_selector = RFE(estimator=xgb_classifier, n_features_to_select=10, step=1)\n",
        "rfe_selector = rfe_selector.fit(X_train, y_train)\n",
        "\n",
        "# 선택된 특징으로 학습\n",
        "selected_features = X_train.columns[rfe_selector.support_]\n",
        "xgb_classifier.fit(X_train[selected_features], y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = xgb_classifier.predict(X_test[selected_features])\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"선택된 특징: {selected_features}\")\n",
        "print(f\"XGBoost 모델 정확도: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPALbfex2NAZ",
        "outputId": "5598a682-0f77-4278-b445-e8f5137cc1a6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "선택된 특징: Index(['education', 'housing', 'loan', 'contact', 'day', 'month', 'duration',\n",
            "       'pdays', 'previous', 'poutcome'],\n",
            "      dtype='object')\n",
            "XGBoost 모델 정확도: 0.8542848611525828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 로지스틱 회귀분석 결과"
      ],
      "metadata": {
        "id": "dCnaG5qV15Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 70세 이상은 이상치로 제거\n",
        "data = data[data['age'] <= 70]\n",
        "\n",
        "# 'job' 칼럼에서 'unknown' 값을 결측치로 처리\n",
        "data['job'] = data['job'].replace('unknown', None)\n",
        "\n",
        "# SimpleImputer로 결측치를 처리 (최빈값으로 대체)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data['job'] = imputer.fit_transform(data[['job']])\n",
        "\n",
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature와 Target 설정\n",
        "X = data.drop('deposit', axis=1)\n",
        "y = data['deposit']\n",
        "\n",
        "# 1. 로지스틱 회귀 모델을 사용하여 p-value를 기반으로 유의미한 변수 선택\n",
        "# 상수항 추가\n",
        "X_with_constant = sm.add_constant(X)\n",
        "\n",
        "# 로지스틱 회귀 모델 적합\n",
        "logit_model = sm.Logit(y, X_with_constant).fit()\n",
        "\n",
        "# p-value가 0.05 이하인 변수 선택\n",
        "selected_features = logit_model.pvalues[logit_model.pvalues < 0.05].index.tolist()\n",
        "\n",
        "# 상수항 제거 (constant 제거)\n",
        "if 'const' in selected_features:\n",
        "    selected_features.remove('const')\n",
        "\n",
        "print(f\"선택된 유의미한 변수들: {selected_features}\")\n",
        "\n",
        "# 2. 선택된 변수로 분류 모델 학습 (XGBoost 예시)\n",
        "X_selected = X[selected_features]  # 선택된 변수로 새로운 데이터셋 구성\n",
        "\n",
        "# Train/Test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 분류 모델 (XGBoost) 학습 및 평가\n",
        "import xgboost as xgb\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = xgb_classifier.predict(X_test)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"XGBoost 모델 정확도: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh8XcmV3z89A",
        "outputId": "3dd52db7-14ea-49e2-9776-f5604250da00"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.468294\n",
            "         Iterations 7\n",
            "선택된 유의미한 변수들: ['age', 'marital', 'education', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome']\n",
            "XGBoost 모델 정확도: 0.8437080161218092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import xgboost as xgb\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "import pandas as pd\n",
        "\n",
        "# 70세 이상은 이상치로 제거\n",
        "data = data[data['age'] <= 70]\n",
        "\n",
        "# 1. \"unknown\" 값을 결측값으로 처리하고, 결측값을 최빈값으로 대체\n",
        "data['job'] = data['job'].replace('unknown', None)\n",
        "data['education'] = data['education'].replace('unknown', None)\n",
        "data['contact'] = data['contact'].replace('unknown', None)\n",
        "data['poutcome'] = data['poutcome'].replace('unknown', None)\n",
        "\n",
        "# SimpleImputer로 결측치를 처리 (최빈값으로 대체)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data[['job', 'education', 'contact', 'poutcome']] = imputer.fit_transform(data[['job', 'education', 'contact', 'poutcome']])\n",
        "\n",
        "# 2. \"duration\" 변수를 제거 (사후 데이터 포함)\n",
        "data = data.drop('duration', axis=1)\n",
        "\n",
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature와 Target 설정\n",
        "X = data.drop('deposit', axis=1)\n",
        "y = data['deposit']\n",
        "\n",
        "# Train/Test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# XGBoost 모델 초기화\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Recursive Feature Elimination (RFE)를 이용한 feature selection\n",
        "rfe_selector = RFE(estimator=xgb_classifier, n_features_to_select=10, step=1)\n",
        "rfe_selector = rfe_selector.fit(X_train, y_train)\n",
        "\n",
        "# 선택된 특징으로 학습\n",
        "selected_features = X_train.columns[rfe_selector.support_]\n",
        "xgb_classifier.fit(X_train[selected_features], y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = xgb_classifier.predict(X_test[selected_features])\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"선택된 특징: {selected_features}\")\n",
        "print(f\"XGBoost 모델 정확도: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE3A8dfp3oNO",
        "outputId": "eb0a6890-cdbb-4355-ac3d-973c11dac7a8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "선택된 특징: Index(['age', 'marital', 'balance', 'housing', 'loan', 'contact', 'day',\n",
            "       'month', 'pdays', 'poutcome'],\n",
            "      dtype='object')\n",
            "XGBoost 모델 정확도: 0.7160346372051358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# 70세 이상은 이상치로 제거\n",
        "data = data[data['age'] <= 70]\n",
        "\n",
        "# 'job', 'education', 'contact', 'poutcome' 칼럼에서 'unknown' 값을 결측치로 처리\n",
        "data['job'] = data['job'].replace('unknown', None)\n",
        "data['education'] = data['education'].replace('unknown', None)\n",
        "data['contact'] = data['contact'].replace('unknown', None)\n",
        "data['poutcome'] = data['poutcome'].replace('unknown', None)\n",
        "\n",
        "# SimpleImputer로 결측치를 최빈값으로 대체\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data[['job', 'education', 'contact', 'poutcome']] = imputer.fit_transform(data[['job', 'education', 'contact', 'poutcome']])\n",
        "\n",
        "# 'duration' 변수 제거 (사후 데이터)\n",
        "data = data.drop('duration', axis=1)\n",
        "\n",
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature와 Target 설정\n",
        "X = data.drop('deposit', axis=1)\n",
        "y = data['deposit']\n",
        "\n",
        "# 1. 로지스틱 회귀 모델을 사용하여 p-value를 기반으로 유의미한 변수 선택\n",
        "# 상수항 추가\n",
        "X_with_constant = sm.add_constant(X)\n",
        "\n",
        "# 로지스틱 회귀 모델 적합\n",
        "logit_model = sm.Logit(y, X_with_constant).fit()\n",
        "\n",
        "# p-value가 0.05 이하인 변수 선택\n",
        "selected_features = logit_model.pvalues[logit_model.pvalues < 0.05].index.tolist()\n",
        "\n",
        "# 상수항 제거 (constant 제거)\n",
        "if 'const' in selected_features:\n",
        "    selected_features.remove('const')\n",
        "\n",
        "print(f\"선택된 유의미한 변수들: {selected_features}\")\n",
        "\n",
        "# 2. 선택된 변수로 분류 모델 학습 (XGBoost 예시)\n",
        "X_selected = X[selected_features]  # 선택된 변수로 새로운 데이터셋 구성\n",
        "\n",
        "# Train/Test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 분류 모델 (XGBoost) 학습 및 평가\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = xgb_classifier.predict(X_test)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"XGBoost 모델 정확도: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7rIVjmT6G-u",
        "outputId": "b1cb99e4-ebf7-4ae7-9da9-40caa7365e49"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.619286\n",
            "         Iterations 6\n",
            "선택된 유의미한 변수들: ['marital', 'education', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'campaign', 'pdays', 'previous', 'poutcome']\n",
            "XGBoost 모델 정확도: 0.7222222222222222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# 70세 이상은 이상치로 제거\n",
        "data = data[data['age'] <= 70]\n",
        "\n",
        "# 'job'과 'age' 칼럼에서 'unknown' 값을 결측치로 처리\n",
        "data['job'] = data['job'].replace('unknown', None)\n",
        "\n",
        "# SimpleImputer로 job 칼럼의 결측치를 최빈값으로 대체\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data['job'] = imputer.fit_transform(data[['job']])\n",
        "\n",
        "# 'duration' 변수 제거 (사후 데이터)\n",
        "data = data.drop('duration', axis=1)\n",
        "\n",
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature와 Target 설정\n",
        "X = data.drop('deposit', axis=1)\n",
        "y = data['deposit']\n",
        "\n",
        "# 1. 로지스틱 회귀 모델을 사용하여 p-value를 기반으로 유의미한 변수 선택\n",
        "# 상수항 추가\n",
        "X_with_constant = sm.add_constant(X)\n",
        "\n",
        "# 로지스틱 회귀 모델 적합\n",
        "logit_model = sm.Logit(y, X_with_constant).fit()\n",
        "\n",
        "# p-value가 0.05 이하인 변수 선택\n",
        "selected_features = logit_model.pvalues[logit_model.pvalues < 0.05].index.tolist()\n",
        "\n",
        "# 상수항 제거 (constant 제거)\n",
        "if 'const' in selected_features:\n",
        "    selected_features.remove('const')\n",
        "\n",
        "print(f\"선택된 유의미한 변수들: {selected_features}\")\n",
        "\n",
        "# 2. 선택된 변수로 분류 모델 학습 (XGBoost 예시)\n",
        "X_selected = X[selected_features]  # 선택된 변수로 새로운 데이터셋 구성\n",
        "\n",
        "# Train/Test 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 분류 모델 (XGBoost) 학습 및 평가\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "y_pred = xgb_classifier.predict(X_test)\n",
        "\n",
        "# 정확도 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"XGBoost 모델 정확도: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "Hx4a3YrA6j7e",
        "outputId": "0a4690bf-b207-4da6-fe11-d71f42ea0475"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-8060ad38925a>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# SimpleImputer로 job 칼럼의 결측치를 최빈값으로 대체\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'most_frequent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 'duration' 변수 제거 (사후 데이터)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4089\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4090\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4091\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4298\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m         \"\"\"\n\u001b[0;32m-> 4300\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5038\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5039\u001b[0m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5042\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 if (\n\u001b[1;32m    610\u001b[0m                     \u001b[0mobject_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;31m# Caller is responsible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance 기반 상위 10개의 피처 선택 및 모델 학습 코드:\n",
        "# 필요한 라이브러리 임포트\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 70세 이상은 이상치로 제거\n",
        "data = data[data['age'] <= 70]\n",
        "\n",
        "# 'job' 칼럼에서 'unknown' 값을 결측치로 처리\n",
        "data['job'] = data['job'].replace('unknown', None)\n",
        "\n",
        "# SimpleImputer로 job 칼럼의 결측치를 최빈값으로 대체 (문자열 형식으로 변환)\n",
        "imputer = SimpleImputer(strategy='most_frequent', missing_values=None)\n",
        "data['job'] = imputer.fit_transform(data[['job']].astype(str))\n",
        "\n",
        "# 'duration' 변수 제거 (사후 데이터)\n",
        "data = data.drop('duration', axis=1)\n",
        "\n",
        "# Label Encoding for categorical columns\n",
        "label_enc = LabelEncoder()\n",
        "data['deposit'] = label_enc.fit_transform(data['deposit'])\n",
        "\n",
        "# Categorical features to be label encoded\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "for col in categorical_columns:\n",
        "    data[col] = label_enc.fit_transform(data[col])\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "numerical_columns = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Feature\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "_mqaErCC6-Xc",
        "outputId": "e96ab54c-7ed6-4d52-da8e-a7e27fad6687"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-8cfafabcdc3e>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# SimpleImputer로 job 칼럼의 결측치를 최빈값으로 대체 (문자열 형식으로 변환)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'most_frequent'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'job'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 'duration' 변수 제거 (사후 데이터)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4089\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4090\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4091\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4298\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m         \"\"\"\n\u001b[0;32m-> 4300\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4302\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5038\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5039\u001b[0m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5042\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 if (\n\u001b[1;32m    610\u001b[0m                     \u001b[0mobject_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;31m# Caller is responsible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f0kc8PrQ7BNF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}